# LXO RunPod Template - CI-Optimized Dockerfile
# Lightweight build for GitHub Actions - PyTorch, ComfyUI, and nodes installed at runtime
# Based on: lum3on/wan2.2_runpod-temp
# Repo: majdsalim/LXOtesting
#
# BUILD_MODE:
#   compute    (default) - ComfyUI foreground on 0.0.0.0:8188 + JupyterLab on 8189
#   serverless           - ComfyUI background on localhost:8188 + handler.py foreground (RunPod Serverless)

# ============================================================================
# Stage 1: Base image with CUDA 12.8.1 (NO PyTorch - installed at runtime)
# ============================================================================
# Using devel image (includes nvcc) for SageAttention2++ compilation at runtime
FROM nvidia/cuda:12.8.1-cudnn-devel-ubuntu24.04 AS base

# Build arguments
ARG BUILD_MODE=compute
# ComfyUI version is handled at runtime by runtime-init.sh
# Set COMFYUI_USE_LATEST=true (default) for latest, or false + COMFYUI_VERSION for pinned

# Environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PIP_PREFER_BINARY=1
ENV PYTHONUNBUFFERED=1
ENV PIP_NO_INPUT=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.12 \
    python3.12-venv \
    python3.12-dev \
    build-essential \
    git \
    wget \
    curl \
    aria2 \
    libgl1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender1 \
    ffmpeg \
    && ln -sf /usr/bin/python3.12 /usr/bin/python \
    && ln -sf /usr/bin/pip3 /usr/bin/pip \
    && apt-get autoremove -y && apt-get clean -y && rm -rf /var/lib/apt/lists/*

# Install uv (fast Python package installer)
RUN wget -qO- https://astral.sh/uv/install.sh | sh \
    && ln -s /root/.local/bin/uv /usr/local/bin/uv \
    && ln -s /root/.local/bin/uvx /usr/local/bin/uvx \
    && uv venv /opt/venv

# Use the virtual environment
ENV PATH="/opt/venv/bin:${PATH}"

# Install comfy-cli and basic dependencies (lightweight)
RUN uv pip install --no-cache comfy-cli pip setuptools wheel \
    && rm -rf /root/.cache/uv && rm -rf /tmp/*

# Stay in root directory
WORKDIR /

# Install RunPod handler dependencies (lightweight)
RUN uv pip install --no-cache runpod requests websocket-client \
    && rm -rf /root/.cache/uv && rm -rf /tmp/*

# Copy extra_model_paths.yaml to /etc for later use in runtime-init
# (We don't create /comfyui yet - let comfy-cli do it at runtime)
# This is done AFTER cleanup to ensure it persists
COPY runpod-worker-comfyui/src/extra_model_paths.yaml /etc/extra_model_paths.yaml

# ============================================================================
# Stage 2: Final Configuration
# ============================================================================
FROM base AS final

WORKDIR /

# Copy handler and scripts from local runpod-worker-comfyui directory
COPY runpod-worker-comfyui/handler.py /handler.py

# Copy model download script
COPY scripts/download_models.sh /scripts/download_models.sh
RUN chmod +x /scripts/download_models.sh

# Copy runtime initialization script (installs ComfyUI, PyTorch, custom nodes at runtime)
COPY scripts/runtime-init.sh /scripts/runtime-init.sh
RUN chmod +x /scripts/runtime-init.sh

# ============================================================================
# Start script generation — differs by BUILD_MODE
# ============================================================================

# --- Shared preamble (both modes) ---
RUN printf '#!/usr/bin/env bash\n\
\n\
echo ""\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║           LXO RunPod Template - Starting Up                       ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
echo ""\n\
\n\
# Run runtime initialization (ComfyUI, PyTorch, custom nodes, SageAttention)\n\
/scripts/runtime-init.sh\n\
\n\
# Use libtcmalloc for better memory management\n\
TCMALLOC="$(ldconfig -p | grep -Po "libtcmalloc.so.\\d" | head -n 1)"\n\
export LD_PRELOAD="${TCMALLOC}"\n\
\n\
# Ensure /comfyui has proper permissions\n\
chmod -R 777 /comfyui\n\
chown -R root:root /comfyui\n\
\n' > /start.sh

# --- Mode-specific section ---
ARG BUILD_MODE=compute

# COMPUTE MODE: JupyterLab + model downloads + ComfyUI foreground (0.0.0.0)
RUN if [ "$BUILD_MODE" = "compute" ]; then \
    printf '# --- COMPUTE MODE ---\n\
echo ""\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  JUPYTERLAB STARTING (Port 8189) - Available NOW!                 ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
echo ""\n\
\n\
# Start JupyterLab IMMEDIATELY (before model downloads)\n\
jupyter lab --config=/root/.jupyter/jupyter_lab_config.py > /var/log/jupyter.log 2>&1 &\n\
JUPYTER_PID=$!\n\
sleep 1\n\
if ps -p $JUPYTER_PID > /dev/null 2>&1; then\n\
    echo "   JupyterLab running (PID: $JUPYTER_PID)"\n\
else\n\
    echo "   WARNING: JupyterLab may have issues - check /var/log/jupyter.log"\n\
fi\n\
echo ""\n\
\n\
# Download models\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  MODEL DOWNLOAD STARTING                                          ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
/scripts/download_models.sh\n\
echo ""\n\
\n\
# Allow operators to tweak verbosity; default is DEBUG\n\
: "${COMFY_LOG_LEVEL:=DEBUG}"\n\
\n\
# VRAM management mode\n\
: "${COMFY_VRAM_MODE:=normalvram}"\n\
VRAM_FLAG=""\n\
case "$COMFY_VRAM_MODE" in\n\
    highvram)  VRAM_FLAG="--highvram" ;;\n\
    gpu-only)  VRAM_FLAG="--gpu-only" ;;\n\
    lowvram)   VRAM_FLAG="--lowvram" ;;\n\
    novram)    VRAM_FLAG="--novram" ;;\n\
    normal*)   VRAM_FLAG="" ;;\n\
    *)         VRAM_FLAG="--highvram" ;;\n\
esac\n\
\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  COMFYUI STARTING (Port 8188) - Compute Mode                      ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
echo "   SageAttention: ENABLED"\n\
echo "   Log Level: ${COMFY_LOG_LEVEL}"\n\
echo "   VRAM Mode: ${COMFY_VRAM_MODE} ${VRAM_FLAG}"\n\
echo ""\n\
\n\
# Start ComfyUI in FOREGROUND (direct browser access on 0.0.0.0:8188)\n\
python -u /comfyui/main.py \\\n\
    --disable-auto-launch \\\n\
    --disable-metadata \\\n\
    --listen 0.0.0.0 \\\n\
    --port 8188 \\\n\
    --verbose "${COMFY_LOG_LEVEL}" \\\n\
    --log-stdout \\\n\
    --use-sage-attention \\\n\
    $VRAM_FLAG\n' >> /start.sh; \
    \
    # SERVERLESS MODE: model downloads + ComfyUI background + handler.py foreground
    else \
    printf '# --- SERVERLESS MODE ---\n\
\n\
# Download models (uses /workspace if network volume attached, else /comfyui/models)\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  MODEL DOWNLOAD STARTING                                          ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
/scripts/download_models.sh\n\
echo ""\n\
\n\
# Allow operators to tweak verbosity; default is DEBUG\n\
: "${COMFY_LOG_LEVEL:=DEBUG}"\n\
\n\
# VRAM management mode\n\
: "${COMFY_VRAM_MODE:=normalvram}"\n\
VRAM_FLAG=""\n\
case "$COMFY_VRAM_MODE" in\n\
    highvram)  VRAM_FLAG="--highvram" ;;\n\
    gpu-only)  VRAM_FLAG="--gpu-only" ;;\n\
    lowvram)   VRAM_FLAG="--lowvram" ;;\n\
    novram)    VRAM_FLAG="--novram" ;;\n\
    normal*)   VRAM_FLAG="" ;;\n\
    *)         VRAM_FLAG="--highvram" ;;\n\
esac\n\
\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  COMFYUI STARTING (Background) - Serverless Mode                   ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
echo "   SageAttention: ENABLED"\n\
echo "   Log Level: ${COMFY_LOG_LEVEL}"\n\
echo "   VRAM Mode: ${COMFY_VRAM_MODE} ${VRAM_FLAG}"\n\
echo "   Listening: localhost:8188 (internal only)"\n\
echo ""\n\
\n\
# Start ComfyUI in BACKGROUND (localhost only — handler.py talks to it internally)\n\
python -u /comfyui/main.py \\\n\
    --disable-auto-launch \\\n\
    --disable-metadata \\\n\
    --verbose "${COMFY_LOG_LEVEL}" \\\n\
    --log-stdout \\\n\
    --use-sage-attention \\\n\
    $VRAM_FLAG &\n\
\n\
echo ""\n\
echo "╔═══════════════════════════════════════════════════════════════════╗"\n\
echo "║  RUNPOD HANDLER STARTING                                           ║"\n\
echo "╚═══════════════════════════════════════════════════════════════════╝"\n\
echo "   Handler connects to ComfyUI at 127.0.0.1:8188"\n\
echo "   Waiting for RunPod jobs..."\n\
echo ""\n\
\n\
# Start RunPod handler in FOREGROUND (receives jobs from RunPod queue)\n\
python -u /handler.py\n' >> /start.sh; \
    fi

RUN chmod +x /start.sh

# Expose ports (serverless only needs 8188 internally, but expose both for flexibility)
EXPOSE 8188 8189

# Set the default command
CMD ["/start.sh"]

# Labels (BUILD_MODE is injected at build time)
ARG BUILD_MODE=compute
LABEL maintainer="majdsalim/LXOtesting"
LABEL description="LXO RunPod template. BUILD_MODE=${BUILD_MODE}. ComfyUI (latest) + runtime-installed PyTorch, nodes, and SageAttention."
LABEL cuda.version="12.8.1"
LABEL pytorch.version="runtime-install"
LABEL comfyui.version="latest (runtime)"
LABEL template.type="ci-optimized"
LABEL build.mode="${BUILD_MODE}"
LABEL ports.comfyui="8188"

